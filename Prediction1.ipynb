{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RNN(Long Short-Term Memory, LSTM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, LSTM, TimeDistributed, RepeatVector\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mergeData():\n",
    "    SaveFile_Name = 'data.csv'\n",
    "    file_list = os.listdir('data')\n",
    "    df = pd.read_csv('data'+'\\\\'+file_list[0])\n",
    "    df.to_csv(SaveFile_Name,encoding=\"utf_8_sig\",index=False)\n",
    "    for i in range(1,len(file_list)):\n",
    "        df = pd.read_csv('data'+'\\\\'+file_list[i])\n",
    "        df.to_csv(SaveFile_Name,encoding=\"utf_8_sig\",index=False, header=False, mode='a+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readData():\n",
    "    train = pd.read_csv(\"data.csv\")\n",
    "    return train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def changeYear(data):\n",
    "    for i in range(0,data.shape[0]):\n",
    "        Date=data[\"日期\"][i].split('/')\n",
    "        year,month,date=Date[0],Date[1],Date[2]\n",
    "        year=str(int(year)+1911)\n",
    "        data.loc[i,\"日期\"]=year+'/'+month+'/'+date\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Augment Features\n",
    "def augFeatures(data):\n",
    "  data[\"日期\"] = pd.to_datetime(data[\"日期\"])\n",
    "  data[\"年\"] = data[\"日期\"].dt.year\n",
    "  data[\"月\"] = data[\"日期\"].dt.month\n",
    "  data[\"日\"] = data[\"日期\"].dt.day\n",
    "  data[\"第幾日\"] = data[\"日期\"].dt.dayofweek\n",
    "  return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(data):\n",
    "    for i in range(0,data.shape[0]):\n",
    "        if data[\"漲跌價差\"][i]=='X0.00':\n",
    "            data.loc[i,\"漲跌價差\"]=str(int(data[\"收盤價\"][i])-int(data[\"收盤價\"][i-1]))\n",
    "    data=data.drop([\"日期\"], axis=1)\n",
    "    data=data.drop([\"成交股數\"], axis=1)\n",
    "    data=data.drop([\"成交金額\"], axis=1)\n",
    "    data=data.drop([\"漲跌價差\"], axis=1)\n",
    "    data=data.drop([\"成交筆數\"], axis=1)\n",
    "    data=data.convert_objects(convert_numeric=True)\n",
    "    datanormalize=data.apply(lambda x: (x - np.mean(x)) / (np.max(x) - np.min(x)))\n",
    "    return datanormalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildTrain(train, pastDay=30, futureDay=5):\n",
    "  X_train, Y_train = [], []\n",
    "  for i in range(train.shape[0]-futureDay-pastDay):\n",
    "    X_train.append(np.array(train.iloc[i:i+pastDay]))\n",
    "    Y_train.append(np.array(train.iloc[i+pastDay:i+pastDay+futureDay][\"開盤價\"]))\n",
    "  return np.array(X_train), np.array(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle(X,Y):\n",
    "  np.random.seed(10)\n",
    "  randomList = np.arange(X.shape[0])\n",
    "  np.random.shuffle(randomList)\n",
    "  return X[randomList], Y[randomList]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 將Training Data取一部份當作Validation Data\n",
    "def splitData(X,Y,rate):\n",
    "  X_train = X[int(X.shape[0]*rate):]\n",
    "  Y_train = Y[int(Y.shape[0]*rate):]\n",
    "  X_val = X[:int(X.shape[0]*rate)]\n",
    "  Y_val = Y[:int(Y.shape[0]*rate)]\n",
    "  return X_train, Y_train, X_val, Y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildOneToOneModel(shape):\n",
    "  model = Sequential()\n",
    "  model.add(LSTM(10, input_length=shape[1], input_dim=shape[2],return_sequences=True))\n",
    "  # output shape: (1, 1)\n",
    "  model.add(TimeDistributed(Dense(1)))    # or use model.add(Dense(1))\n",
    "  model.compile(loss=\"mse\", optimizer=\"adam\")\n",
    "  model.summary()\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:10: FutureWarning: convert_objects is deprecated.  To re-infer data dtypes for object columns, use DataFrame.infer_objects()\n",
      "For all other conversions use the data-type specific converters pd.to_datetime, pd.to_timedelta and pd.to_numeric.\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "C:\\Users\\admin\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: The `input_dim` and `input_length` arguments in recurrent layers are deprecated. Use `input_shape` instead.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\admin\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(10, return_sequences=True, input_shape=(1, 8))`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_2 (LSTM)                (None, 1, 10)             760       \n",
      "_________________________________________________________________\n",
      "time_distributed_2 (TimeDist (None, 1, 1)              11        \n",
      "=================================================================\n",
      "Total params: 771\n",
      "Trainable params: 771\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 5571 samples, validate on 618 samples\n",
      "Epoch 1/1000\n",
      "5571/5571 [==============================] - 1s 144us/step - loss: 0.0196 - val_loss: 0.0029\n",
      "Epoch 2/1000\n",
      "5571/5571 [==============================] - 0s 32us/step - loss: 7.4295e-04 - val_loss: 2.2842e-04\n",
      "Epoch 3/1000\n",
      "5571/5571 [==============================] - 0s 27us/step - loss: 2.2631e-04 - val_loss: 1.3783e-04\n",
      "Epoch 4/1000\n",
      "5571/5571 [==============================] - 0s 26us/step - loss: 1.6550e-04 - val_loss: 9.5375e-05\n",
      "Epoch 5/1000\n",
      "5571/5571 [==============================] - 0s 26us/step - loss: 1.3872e-04 - val_loss: 7.9697e-05\n",
      "Epoch 6/1000\n",
      "5571/5571 [==============================] - 0s 27us/step - loss: 1.2926e-04 - val_loss: 7.4978e-05\n",
      "Epoch 7/1000\n",
      "5571/5571 [==============================] - 0s 27us/step - loss: 1.2601e-04 - val_loss: 7.2276e-05\n",
      "Epoch 8/1000\n",
      "5571/5571 [==============================] - 0s 26us/step - loss: 1.2454e-04 - val_loss: 7.1135e-05\n",
      "Epoch 9/1000\n",
      "5571/5571 [==============================] - 0s 26us/step - loss: 1.2322e-04 - val_loss: 7.3636e-05\n",
      "Epoch 10/1000\n",
      "5571/5571 [==============================] - 0s 26us/step - loss: 1.2326e-04 - val_loss: 7.2186e-05\n",
      "Epoch 11/1000\n",
      "5571/5571 [==============================] - 0s 26us/step - loss: 1.2273e-04 - val_loss: 7.2977e-05\n",
      "Epoch 12/1000\n",
      "5571/5571 [==============================] - 0s 26us/step - loss: 1.2297e-04 - val_loss: 7.0148e-05\n",
      "Epoch 13/1000\n",
      "5571/5571 [==============================] - 0s 27us/step - loss: 1.2150e-04 - val_loss: 6.9639e-05\n",
      "Epoch 14/1000\n",
      "5571/5571 [==============================] - 0s 27us/step - loss: 1.2132e-04 - val_loss: 6.8706e-05\n",
      "Epoch 15/1000\n",
      "5571/5571 [==============================] - 0s 26us/step - loss: 1.2151e-04 - val_loss: 6.8707e-05\n",
      "Epoch 16/1000\n",
      "5571/5571 [==============================] - 0s 26us/step - loss: 1.2052e-04 - val_loss: 6.8530e-05\n",
      "Epoch 17/1000\n",
      "5571/5571 [==============================] - 0s 26us/step - loss: 1.2090e-04 - val_loss: 7.5497e-05\n",
      "Epoch 18/1000\n",
      "5571/5571 [==============================] - 0s 27us/step - loss: 1.2094e-04 - val_loss: 7.0919e-05\n",
      "Epoch 19/1000\n",
      "5571/5571 [==============================] - 0s 27us/step - loss: 1.2187e-04 - val_loss: 6.8054e-05\n",
      "Epoch 20/1000\n",
      "5571/5571 [==============================] - 0s 26us/step - loss: 1.1952e-04 - val_loss: 7.1047e-05\n",
      "Epoch 21/1000\n",
      "5571/5571 [==============================] - 0s 26us/step - loss: 1.1947e-04 - val_loss: 6.8305e-05\n",
      "Epoch 22/1000\n",
      "5571/5571 [==============================] - 0s 32us/step - loss: 1.1907e-04 - val_loss: 6.7427e-05\n",
      "Epoch 23/1000\n",
      "5571/5571 [==============================] - 0s 26us/step - loss: 1.1927e-04 - val_loss: 6.9764e-05\n",
      "Epoch 24/1000\n",
      "5571/5571 [==============================] - 0s 26us/step - loss: 1.1871e-04 - val_loss: 6.9006e-05\n",
      "Epoch 25/1000\n",
      "5571/5571 [==============================] - 0s 30us/step - loss: 1.1941e-04 - val_loss: 6.7334e-05\n",
      "Epoch 26/1000\n",
      "5571/5571 [==============================] - 0s 30us/step - loss: 1.1819e-04 - val_loss: 6.7739e-05\n",
      "Epoch 27/1000\n",
      "5571/5571 [==============================] - 0s 29us/step - loss: 1.1796e-04 - val_loss: 6.9458e-05\n",
      "Epoch 28/1000\n",
      "5571/5571 [==============================] - 0s 27us/step - loss: 1.1781e-04 - val_loss: 6.7402e-05\n",
      "Epoch 29/1000\n",
      "5571/5571 [==============================] - 0s 27us/step - loss: 1.1783e-04 - val_loss: 7.0639e-05\n",
      "Epoch 30/1000\n",
      "5571/5571 [==============================] - 0s 26us/step - loss: 1.1922e-04 - val_loss: 6.9740e-05\n",
      "Epoch 31/1000\n",
      "5571/5571 [==============================] - 0s 27us/step - loss: 1.1667e-04 - val_loss: 6.5375e-05\n",
      "Epoch 32/1000\n",
      "5571/5571 [==============================] - 0s 26us/step - loss: 1.1633e-04 - val_loss: 6.5537e-05\n",
      "Epoch 33/1000\n",
      "5571/5571 [==============================] - 0s 27us/step - loss: 1.1627e-04 - val_loss: 6.5771e-05\n",
      "Epoch 34/1000\n",
      "5571/5571 [==============================] - 0s 27us/step - loss: 1.1635e-04 - val_loss: 6.8490e-05\n",
      "Epoch 35/1000\n",
      "5571/5571 [==============================] - 0s 26us/step - loss: 1.1616e-04 - val_loss: 6.6272e-05\n",
      "Epoch 36/1000\n",
      "5571/5571 [==============================] - 0s 26us/step - loss: 1.1644e-04 - val_loss: 6.5437e-05\n",
      "Epoch 37/1000\n",
      "5571/5571 [==============================] - 0s 26us/step - loss: 1.1435e-04 - val_loss: 7.0776e-05\n",
      "Epoch 38/1000\n",
      "5571/5571 [==============================] - 0s 27us/step - loss: 1.1702e-04 - val_loss: 6.4417e-05\n",
      "Epoch 39/1000\n",
      "5571/5571 [==============================] - 0s 31us/step - loss: 1.1480e-04 - val_loss: 6.4274e-05\n",
      "Epoch 40/1000\n",
      "5571/5571 [==============================] - 0s 30us/step - loss: 1.1356e-04 - val_loss: 6.2905e-05\n",
      "Epoch 41/1000\n",
      "5571/5571 [==============================] - 0s 26us/step - loss: 1.1249e-04 - val_loss: 6.3503e-05\n",
      "Epoch 42/1000\n",
      "5571/5571 [==============================] - 0s 26us/step - loss: 1.1414e-04 - val_loss: 7.0287e-05\n",
      "Epoch 43/1000\n",
      "5571/5571 [==============================] - 0s 25us/step - loss: 1.1405e-04 - val_loss: 6.7343e-05\n",
      "Epoch 44/1000\n",
      "5571/5571 [==============================] - 0s 25us/step - loss: 1.1327e-04 - val_loss: 6.4777e-05\n",
      "Epoch 45/1000\n",
      "5571/5571 [==============================] - 0s 25us/step - loss: 1.1223e-04 - val_loss: 6.7274e-05\n",
      "Epoch 46/1000\n",
      "5571/5571 [==============================] - 0s 25us/step - loss: 1.1178e-04 - val_loss: 6.3326e-05\n",
      "Epoch 47/1000\n",
      "5571/5571 [==============================] - 0s 25us/step - loss: 1.1074e-04 - val_loss: 6.3473e-05\n",
      "Epoch 48/1000\n",
      "5571/5571 [==============================] - 0s 27us/step - loss: 1.0981e-04 - val_loss: 6.2368e-05\n",
      "Epoch 49/1000\n",
      "5571/5571 [==============================] - 0s 33us/step - loss: 1.1249e-04 - val_loss: 6.6312e-05\n",
      "Epoch 50/1000\n",
      "5571/5571 [==============================] - 0s 31us/step - loss: 1.0999e-04 - val_loss: 5.9229e-05\n",
      "Epoch 51/1000\n",
      "5571/5571 [==============================] - 0s 28us/step - loss: 1.0962e-04 - val_loss: 6.5372e-05\n",
      "Epoch 52/1000\n",
      "5571/5571 [==============================] - 0s 27us/step - loss: 1.0822e-04 - val_loss: 6.6010e-05\n",
      "Epoch 53/1000\n",
      "5571/5571 [==============================] - 0s 26us/step - loss: 1.0787e-04 - val_loss: 6.6499e-05\n",
      "Epoch 54/1000\n",
      "5571/5571 [==============================] - 0s 25us/step - loss: 1.0978e-04 - val_loss: 6.1071e-05\n",
      "Epoch 55/1000\n",
      "5571/5571 [==============================] - 0s 26us/step - loss: 1.0771e-04 - val_loss: 5.7863e-05\n",
      "Epoch 56/1000\n",
      "5571/5571 [==============================] - 0s 26us/step - loss: 1.0894e-04 - val_loss: 6.0071e-05\n",
      "Epoch 57/1000\n",
      "5571/5571 [==============================] - 0s 25us/step - loss: 1.0706e-04 - val_loss: 5.8195e-05\n",
      "Epoch 58/1000\n",
      "5571/5571 [==============================] - 0s 26us/step - loss: 1.0740e-04 - val_loss: 5.7430e-05\n",
      "Epoch 59/1000\n",
      "5571/5571 [==============================] - 0s 29us/step - loss: 1.0762e-04 - val_loss: 6.1083e-05\n",
      "Epoch 60/1000\n",
      "5571/5571 [==============================] - 0s 26us/step - loss: 1.0628e-04 - val_loss: 6.7629e-05\n",
      "Epoch 61/1000\n",
      "5571/5571 [==============================] - 0s 26us/step - loss: 1.0583e-04 - val_loss: 5.6323e-05\n",
      "Epoch 62/1000\n",
      "5571/5571 [==============================] - 0s 28us/step - loss: 1.0450e-04 - val_loss: 5.5576e-05\n",
      "Epoch 63/1000\n",
      "5571/5571 [==============================] - 0s 27us/step - loss: 1.0787e-04 - val_loss: 5.6413e-05\n",
      "Epoch 64/1000\n",
      "5571/5571 [==============================] - 0s 26us/step - loss: 1.0442e-04 - val_loss: 6.1892e-05\n",
      "Epoch 65/1000\n",
      "5571/5571 [==============================] - 0s 26us/step - loss: 1.0551e-04 - val_loss: 5.6369e-05\n",
      "Epoch 66/1000\n",
      "5571/5571 [==============================] - 0s 28us/step - loss: 1.0314e-04 - val_loss: 5.6746e-05\n",
      "Epoch 67/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5571/5571 [==============================] - 0s 27us/step - loss: 1.0628e-04 - val_loss: 6.0358e-05\n",
      "Epoch 68/1000\n",
      "5571/5571 [==============================] - 0s 25us/step - loss: 1.0273e-04 - val_loss: 5.8279e-05\n",
      "Epoch 69/1000\n",
      "5571/5571 [==============================] - 0s 25us/step - loss: 1.0285e-04 - val_loss: 5.9159e-05\n",
      "Epoch 70/1000\n",
      "5571/5571 [==============================] - 0s 27us/step - loss: 1.0260e-04 - val_loss: 5.3375e-05\n",
      "Epoch 71/1000\n",
      "5571/5571 [==============================] - 0s 26us/step - loss: 1.0387e-04 - val_loss: 5.5615e-05\n",
      "Epoch 72/1000\n",
      "5571/5571 [==============================] - 0s 25us/step - loss: 1.0201e-04 - val_loss: 5.5090e-05\n",
      "Epoch 73/1000\n",
      "5571/5571 [==============================] - 0s 25us/step - loss: 1.0228e-04 - val_loss: 5.3439e-05\n",
      "Epoch 74/1000\n",
      "5571/5571 [==============================] - 0s 28us/step - loss: 1.0156e-04 - val_loss: 6.0489e-05\n",
      "Epoch 75/1000\n",
      "5571/5571 [==============================] - 0s 30us/step - loss: 1.0021e-04 - val_loss: 5.9741e-05\n",
      "Epoch 76/1000\n",
      "5571/5571 [==============================] - 0s 29us/step - loss: 1.0283e-04 - val_loss: 5.7264e-05\n",
      "Epoch 77/1000\n",
      "5571/5571 [==============================] - 0s 32us/step - loss: 1.0400e-04 - val_loss: 5.4935e-05\n",
      "Epoch 78/1000\n",
      "5571/5571 [==============================] - 0s 32us/step - loss: 1.0080e-04 - val_loss: 5.4806e-05\n",
      "Epoch 79/1000\n",
      "5571/5571 [==============================] - 0s 29us/step - loss: 9.9290e-05 - val_loss: 6.9663e-05\n",
      "Epoch 80/1000\n",
      "5571/5571 [==============================] - 0s 31us/step - loss: 1.0332e-04 - val_loss: 6.0663e-05\n",
      "Epoch 81/1000\n",
      "5571/5571 [==============================] - 0s 30us/step - loss: 9.9133e-05 - val_loss: 5.2532e-05\n",
      "Epoch 82/1000\n",
      "5571/5571 [==============================] - 0s 26us/step - loss: 9.9017e-05 - val_loss: 5.2557e-05\n",
      "Epoch 83/1000\n",
      "5571/5571 [==============================] - 0s 26us/step - loss: 9.8089e-05 - val_loss: 5.4367e-05\n",
      "Epoch 84/1000\n",
      "5571/5571 [==============================] - 0s 26us/step - loss: 9.8747e-05 - val_loss: 5.1608e-05\n",
      "Epoch 85/1000\n",
      "5571/5571 [==============================] - 0s 28us/step - loss: 9.8229e-05 - val_loss: 5.4935e-05\n",
      "Epoch 86/1000\n",
      "5571/5571 [==============================] - 0s 26us/step - loss: 9.8779e-05 - val_loss: 5.3561e-05\n",
      "Epoch 87/1000\n",
      "5571/5571 [==============================] - 0s 25us/step - loss: 9.8346e-05 - val_loss: 5.3554e-05\n",
      "Epoch 88/1000\n",
      "5571/5571 [==============================] - 0s 26us/step - loss: 9.7814e-05 - val_loss: 5.2663e-05\n",
      "Epoch 89/1000\n",
      "5571/5571 [==============================] - 0s 27us/step - loss: 9.9268e-05 - val_loss: 5.0861e-05\n",
      "Epoch 90/1000\n",
      "5571/5571 [==============================] - 0s 27us/step - loss: 9.7034e-05 - val_loss: 7.4905e-05\n",
      "Epoch 91/1000\n",
      "5571/5571 [==============================] - 0s 25us/step - loss: 9.9138e-05 - val_loss: 5.4909e-05\n",
      "Epoch 92/1000\n",
      "5571/5571 [==============================] - 0s 26us/step - loss: 9.8975e-05 - val_loss: 4.9417e-05\n",
      "Epoch 93/1000\n",
      "5571/5571 [==============================] - 0s 25us/step - loss: 9.6343e-05 - val_loss: 5.2982e-05\n",
      "Epoch 94/1000\n",
      "5571/5571 [==============================] - 0s 29us/step - loss: 9.9327e-05 - val_loss: 5.1725e-05\n",
      "Epoch 95/1000\n",
      "5571/5571 [==============================] - 0s 27us/step - loss: 9.6594e-05 - val_loss: 4.9461e-05\n",
      "Epoch 96/1000\n",
      "5571/5571 [==============================] - 0s 25us/step - loss: 9.6530e-05 - val_loss: 4.9630e-05\n",
      "Epoch 97/1000\n",
      "5571/5571 [==============================] - 0s 27us/step - loss: 9.7550e-05 - val_loss: 4.9691e-05\n",
      "Epoch 98/1000\n",
      "5571/5571 [==============================] - 0s 28us/step - loss: 9.7171e-05 - val_loss: 5.2417e-05\n",
      "Epoch 99/1000\n",
      "5571/5571 [==============================] - 0s 27us/step - loss: 9.7892e-05 - val_loss: 5.0620e-05\n",
      "Epoch 100/1000\n",
      "5571/5571 [==============================] - 0s 25us/step - loss: 9.6200e-05 - val_loss: 5.1616e-05\n",
      "Epoch 101/1000\n",
      "5571/5571 [==============================] - 0s 26us/step - loss: 9.8861e-05 - val_loss: 4.9181e-05\n",
      "Epoch 102/1000\n",
      "5571/5571 [==============================] - 0s 28us/step - loss: 9.5903e-05 - val_loss: 5.1068e-05\n",
      "Epoch 103/1000\n",
      "5571/5571 [==============================] - 0s 26us/step - loss: 9.5676e-05 - val_loss: 5.6500e-05\n",
      "Epoch 104/1000\n",
      "5571/5571 [==============================] - 0s 26us/step - loss: 9.6925e-05 - val_loss: 4.9669e-05\n",
      "Epoch 105/1000\n",
      "5571/5571 [==============================] - 0s 25us/step - loss: 9.6307e-05 - val_loss: 4.7672e-05\n",
      "Epoch 106/1000\n",
      "5571/5571 [==============================] - 0s 27us/step - loss: 9.5729e-05 - val_loss: 5.0296e-05\n",
      "Epoch 107/1000\n",
      "5571/5571 [==============================] - 0s 27us/step - loss: 9.4730e-05 - val_loss: 5.0097e-05\n",
      "Epoch 108/1000\n",
      "5571/5571 [==============================] - 0s 25us/step - loss: 9.5785e-05 - val_loss: 5.9441e-05\n",
      "Epoch 109/1000\n",
      "5571/5571 [==============================] - 0s 26us/step - loss: 9.6850e-05 - val_loss: 5.1060e-05\n",
      "Epoch 110/1000\n",
      "5571/5571 [==============================] - 0s 28us/step - loss: 9.4340e-05 - val_loss: 5.2403e-05\n",
      "Epoch 111/1000\n",
      "5571/5571 [==============================] - 0s 26us/step - loss: 9.7388e-05 - val_loss: 4.9402e-05\n",
      "Epoch 112/1000\n",
      "5571/5571 [==============================] - 0s 25us/step - loss: 9.6464e-05 - val_loss: 5.1487e-05\n",
      "Epoch 113/1000\n",
      "5571/5571 [==============================] - 0s 26us/step - loss: 9.4416e-05 - val_loss: 4.8829e-05\n",
      "Epoch 114/1000\n",
      "5571/5571 [==============================] - 0s 27us/step - loss: 9.5415e-05 - val_loss: 5.7132e-05\n",
      "Epoch 115/1000\n",
      "5571/5571 [==============================] - 0s 28us/step - loss: 9.4559e-05 - val_loss: 4.6958e-05\n",
      "Epoch 116/1000\n",
      "5571/5571 [==============================] - 0s 26us/step - loss: 9.4527e-05 - val_loss: 5.0582e-05\n",
      "Epoch 117/1000\n",
      "5571/5571 [==============================] - 0s 26us/step - loss: 9.4112e-05 - val_loss: 5.3756e-05\n",
      "Epoch 118/1000\n",
      "5571/5571 [==============================] - 0s 26us/step - loss: 9.4178e-05 - val_loss: 4.9206e-05\n",
      "Epoch 119/1000\n",
      "5571/5571 [==============================] - 0s 27us/step - loss: 9.5740e-05 - val_loss: 4.7855e-05\n",
      "Epoch 120/1000\n",
      "5571/5571 [==============================] - 0s 27us/step - loss: 9.3434e-05 - val_loss: 4.8335e-05\n",
      "Epoch 121/1000\n",
      "5571/5571 [==============================] - 0s 25us/step - loss: 9.4369e-05 - val_loss: 4.9222e-05\n",
      "Epoch 122/1000\n",
      "5571/5571 [==============================] - 0s 25us/step - loss: 9.5965e-05 - val_loss: 4.8652e-05\n",
      "Epoch 123/1000\n",
      "5571/5571 [==============================] - 0s 26us/step - loss: 9.6145e-05 - val_loss: 4.6991e-05\n",
      "Epoch 124/1000\n",
      "5571/5571 [==============================] - 0s 28us/step - loss: 9.5248e-05 - val_loss: 4.7191e-05\n",
      "Epoch 125/1000\n",
      "5571/5571 [==============================] - 0s 27us/step - loss: 9.2993e-05 - val_loss: 4.6762e-05\n",
      "Epoch 126/1000\n",
      "5571/5571 [==============================] - 0s 25us/step - loss: 9.3047e-05 - val_loss: 4.9269e-05\n",
      "Epoch 127/1000\n",
      "5571/5571 [==============================] - 0s 30us/step - loss: 9.3961e-05 - val_loss: 5.4725e-05\n",
      "Epoch 128/1000\n",
      "5571/5571 [==============================] - 0s 29us/step - loss: 9.4648e-05 - val_loss: 5.1755e-05\n",
      "Epoch 129/1000\n",
      "5571/5571 [==============================] - 0s 26us/step - loss: 9.6128e-05 - val_loss: 5.5218e-05\n",
      "Epoch 130/1000\n",
      "5571/5571 [==============================] - 0s 26us/step - loss: 9.3135e-05 - val_loss: 4.7668e-05\n",
      "Epoch 131/1000\n",
      "5571/5571 [==============================] - 0s 28us/step - loss: 9.3681e-05 - val_loss: 4.8559e-05\n",
      "Epoch 132/1000\n",
      "5571/5571 [==============================] - 0s 26us/step - loss: 9.5746e-05 - val_loss: 5.0415e-05\n",
      "Epoch 133/1000\n",
      "5571/5571 [==============================] - 0s 25us/step - loss: 9.4439e-05 - val_loss: 5.4581e-05\n",
      "Epoch 134/1000\n",
      "5571/5571 [==============================] - 0s 26us/step - loss: 9.7146e-05 - val_loss: 5.0854e-05\n",
      "Epoch 135/1000\n",
      "5571/5571 [==============================] - 0s 29us/step - loss: 9.4050e-05 - val_loss: 4.8974e-05\n",
      "Epoch 00135: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x831e94af28>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "mergeData()\n",
    "train=readData()\n",
    "train=changeYear(train)\n",
    "train=augFeatures(train)\n",
    "train=normalize(train)\n",
    "train_x, train_y = buildTrain(train, 1, 1)\n",
    "train_x, train_y = shuffle(train_x, train_y )\n",
    "\n",
    "# split training data and validation data\n",
    "train_x, train_y , val_x, val_y = splitData(train_x, train_y , 0.1)\n",
    "train_y = train_y[:,np.newaxis]\n",
    "val_y = val_y[:,np.newaxis]\n",
    "\n",
    "model = buildOneToOneModel(train_x.shape)\n",
    "callback = EarlyStopping(monitor=\"loss\", patience=10, verbose=1, mode=\"auto\")\n",
    "\n",
    "model.fit(train_x, train_y, epochs=1000, batch_size=50, validation_data=(val_x, val_y), callbacks=[callback])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "618/618 [==============================] - 0s 16us/step\n",
      "4.897444198576019e-05\n"
     ]
    }
   ],
   "source": [
    "scores= model.evaluate(val_x, val_y,verbose=1)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
