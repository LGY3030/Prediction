{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RNN(Long Short-Term Memory, LSTM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, LSTM, TimeDistributed, RepeatVector\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mergeData():\n",
    "    SaveFile_Name = 'data.csv'\n",
    "    file_list = os.listdir('data')\n",
    "    df = pd.read_csv('data'+'\\\\'+file_list[0])\n",
    "    df.to_csv(SaveFile_Name,encoding=\"utf_8_sig\",index=False)\n",
    "    for i in range(1,len(file_list)):\n",
    "        df = pd.read_csv('data'+'\\\\'+file_list[i])\n",
    "        df.to_csv(SaveFile_Name,encoding=\"utf_8_sig\",index=False, header=False, mode='a+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readData():\n",
    "    train = pd.read_csv(\"data.csv\")\n",
    "    return train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def changeYear(data):\n",
    "    for i in range(0,data.shape[0]):\n",
    "        Date=data[\"日期\"][i].split('/')\n",
    "        year,month,date=Date[0],Date[1],Date[2]\n",
    "        year=str(int(year)+1911)\n",
    "        data.loc[i,\"日期\"]=year+'/'+month+'/'+date\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Augment Features\n",
    "def augFeatures(data):\n",
    "  data[\"日期\"] = pd.to_datetime(data[\"日期\"])\n",
    "  data[\"年\"] = data[\"日期\"].dt.year\n",
    "  data[\"月\"] = data[\"日期\"].dt.month\n",
    "  data[\"日\"] = data[\"日期\"].dt.day\n",
    "  data[\"第幾日\"] = data[\"日期\"].dt.dayofweek\n",
    "  return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(data):\n",
    "    for i in range(0,data.shape[0]):\n",
    "        if data[\"漲跌價差\"][i]=='X0.00':\n",
    "            data.loc[i,\"漲跌價差\"]=str(int(data[\"收盤價\"][i])-int(data[\"收盤價\"][i-1]))\n",
    "    data=data.drop([\"日期\"], axis=1)\n",
    "    data=data.drop([\"成交股數\"], axis=1)\n",
    "    data=data.drop([\"成交金額\"], axis=1)\n",
    "    data=data.drop([\"漲跌價差\"], axis=1)\n",
    "    data=data.drop([\"成交筆數\"], axis=1)\n",
    "    data=data.convert_objects(convert_numeric=True)\n",
    "    datanormalize=data.apply(lambda x: (x - np.mean(x)) / (np.max(x) - np.min(x)))\n",
    "    return datanormalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildTrain(train, pastDay=30, futureDay=5):\n",
    "  X_train, Y_train = [], []\n",
    "  for i in range(train.shape[0]-futureDay-pastDay):\n",
    "    X_train.append(np.array(train.iloc[i:i+pastDay]))\n",
    "    Y_train.append(np.array(train.iloc[i+pastDay:i+pastDay+futureDay][\"開盤價\"]))\n",
    "  return np.array(X_train), np.array(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle(X,Y):\n",
    "  np.random.seed(10)\n",
    "  randomList = np.arange(X.shape[0])\n",
    "  np.random.shuffle(randomList)\n",
    "  return X[randomList], Y[randomList]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 將Training Data取一部份當作Validation Data\n",
    "def splitData(X,Y,rate):\n",
    "  X_train = X[int(X.shape[0]*rate):]\n",
    "  Y_train = Y[int(Y.shape[0]*rate):]\n",
    "  X_val = X[:int(X.shape[0]*rate)]\n",
    "  Y_val = Y[:int(Y.shape[0]*rate)]\n",
    "  return X_train, Y_train, X_val, Y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildOneToOneModel(shape):\n",
    "  model = Sequential()\n",
    "  model.add(LSTM(10, input_length=shape[1], input_dim=shape[2],return_sequences=True))\n",
    "  # output shape: (1, 1)\n",
    "  model.add(TimeDistributed(Dense(1)))    # or use model.add(Dense(1))\n",
    "  model.compile(loss=\"mse\", optimizer=\"adam\")\n",
    "  model.summary()\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:10: FutureWarning: convert_objects is deprecated.  To re-infer data dtypes for object columns, use DataFrame.infer_objects()\n",
      "For all other conversions use the data-type specific converters pd.to_datetime, pd.to_timedelta and pd.to_numeric.\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "C:\\Users\\admin\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: The `input_dim` and `input_length` arguments in recurrent layers are deprecated. Use `input_shape` instead.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\admin\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(10, input_shape=(1, 8), return_sequences=True)`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_3 (LSTM)                (None, 1, 10)             760       \n",
      "_________________________________________________________________\n",
      "time_distributed_3 (TimeDist (None, 1, 1)              11        \n",
      "=================================================================\n",
      "Total params: 771\n",
      "Trainable params: 771\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 5571 samples, validate on 618 samples\n",
      "Epoch 1/1000\n",
      "5571/5571 [==============================] - 1s 132us/step - loss: 0.0331 - val_loss: 0.0224\n",
      "Epoch 2/1000\n",
      "5571/5571 [==============================] - 0s 11us/step - loss: 0.0135 - val_loss: 0.0066\n",
      "Epoch 3/1000\n",
      "5571/5571 [==============================] - 0s 11us/step - loss: 0.0030 - val_loss: 9.6957e-04\n",
      "Epoch 4/1000\n",
      "5571/5571 [==============================] - 0s 9us/step - loss: 5.3603e-04 - val_loss: 3.1170e-04\n",
      "Epoch 5/1000\n",
      "5571/5571 [==============================] - 0s 9us/step - loss: 3.1264e-04 - val_loss: 2.3904e-04\n",
      "Epoch 6/1000\n",
      "5571/5571 [==============================] - 0s 9us/step - loss: 2.5427e-04 - val_loss: 1.8534e-04\n",
      "Epoch 7/1000\n",
      "5571/5571 [==============================] - 0s 10us/step - loss: 2.1151e-04 - val_loss: 1.4555e-04\n",
      "Epoch 8/1000\n",
      "5571/5571 [==============================] - 0s 10us/step - loss: 1.8032e-04 - val_loss: 1.1799e-04\n",
      "Epoch 9/1000\n",
      "5571/5571 [==============================] - 0s 13us/step - loss: 1.5880e-04 - val_loss: 9.9259e-05\n",
      "Epoch 10/1000\n",
      "5571/5571 [==============================] - 0s 10us/step - loss: 1.4441e-04 - val_loss: 8.8055e-05\n",
      "Epoch 11/1000\n",
      "5571/5571 [==============================] - 0s 10us/step - loss: 1.3543e-04 - val_loss: 8.0187e-05\n",
      "Epoch 12/1000\n",
      "5571/5571 [==============================] - 0s 10us/step - loss: 1.3003e-04 - val_loss: 7.5745e-05\n",
      "Epoch 13/1000\n",
      "5571/5571 [==============================] - 0s 11us/step - loss: 1.2658e-04 - val_loss: 7.2969e-05\n",
      "Epoch 14/1000\n",
      "5571/5571 [==============================] - 0s 12us/step - loss: 1.2503e-04 - val_loss: 7.5957e-05\n",
      "Epoch 15/1000\n",
      "5571/5571 [==============================] - 0s 11us/step - loss: 1.2362e-04 - val_loss: 7.0750e-05\n",
      "Epoch 16/1000\n",
      "5571/5571 [==============================] - 0s 11us/step - loss: 1.2242e-04 - val_loss: 7.1531e-05\n",
      "Epoch 17/1000\n",
      "5571/5571 [==============================] - 0s 11us/step - loss: 1.2215e-04 - val_loss: 7.0275e-05\n",
      "Epoch 18/1000\n",
      "5571/5571 [==============================] - 0s 10us/step - loss: 1.2190e-04 - val_loss: 7.0478e-05\n",
      "Epoch 19/1000\n",
      "5571/5571 [==============================] - 0s 11us/step - loss: 1.2140e-04 - val_loss: 6.9898e-05\n",
      "Epoch 20/1000\n",
      "5571/5571 [==============================] - 0s 10us/step - loss: 1.2102e-04 - val_loss: 7.0240e-05\n",
      "Epoch 21/1000\n",
      "5571/5571 [==============================] - 0s 10us/step - loss: 1.2104e-04 - val_loss: 6.9660e-05\n",
      "Epoch 22/1000\n",
      "5571/5571 [==============================] - 0s 9us/step - loss: 1.2065e-04 - val_loss: 6.9734e-05\n",
      "Epoch 23/1000\n",
      "5571/5571 [==============================] - 0s 10us/step - loss: 1.2068e-04 - val_loss: 6.9683e-05\n",
      "Epoch 24/1000\n",
      "5571/5571 [==============================] - 0s 10us/step - loss: 1.2054e-04 - val_loss: 7.0451e-05\n",
      "Epoch 25/1000\n",
      "5571/5571 [==============================] - 0s 9us/step - loss: 1.2052e-04 - val_loss: 7.0497e-05\n",
      "Epoch 26/1000\n",
      "5571/5571 [==============================] - 0s 10us/step - loss: 1.2031e-04 - val_loss: 6.8568e-05\n",
      "Epoch 27/1000\n",
      "5571/5571 [==============================] - 0s 10us/step - loss: 1.1996e-04 - val_loss: 6.8629e-05\n",
      "Epoch 28/1000\n",
      "5571/5571 [==============================] - 0s 9us/step - loss: 1.2000e-04 - val_loss: 6.8195e-05\n",
      "Epoch 29/1000\n",
      "5571/5571 [==============================] - 0s 9us/step - loss: 1.1942e-04 - val_loss: 6.8457e-05\n",
      "Epoch 30/1000\n",
      "5571/5571 [==============================] - 0s 9us/step - loss: 1.2025e-04 - val_loss: 7.2011e-05\n",
      "Epoch 31/1000\n",
      "5571/5571 [==============================] - 0s 9us/step - loss: 1.1929e-04 - val_loss: 6.7933e-05\n",
      "Epoch 32/1000\n",
      "5571/5571 [==============================] - 0s 9us/step - loss: 1.1905e-04 - val_loss: 6.8428e-05\n",
      "Epoch 33/1000\n",
      "5571/5571 [==============================] - 0s 10us/step - loss: 1.1895e-04 - val_loss: 6.8119e-05\n",
      "Epoch 34/1000\n",
      "5571/5571 [==============================] - 0s 9us/step - loss: 1.1838e-04 - val_loss: 6.8451e-05\n",
      "Epoch 35/1000\n",
      "5571/5571 [==============================] - 0s 9us/step - loss: 1.1913e-04 - val_loss: 6.7369e-05\n",
      "Epoch 36/1000\n",
      "5571/5571 [==============================] - 0s 9us/step - loss: 1.1890e-04 - val_loss: 6.8775e-05\n",
      "Epoch 37/1000\n",
      "5571/5571 [==============================] - 0s 9us/step - loss: 1.1860e-04 - val_loss: 6.7852e-05\n",
      "Epoch 38/1000\n",
      "5571/5571 [==============================] - 0s 10us/step - loss: 1.1838e-04 - val_loss: 6.8274e-05\n",
      "Epoch 39/1000\n",
      "5571/5571 [==============================] - 0s 9us/step - loss: 1.1770e-04 - val_loss: 6.6916e-05\n",
      "Epoch 40/1000\n",
      "5571/5571 [==============================] - 0s 9us/step - loss: 1.1770e-04 - val_loss: 6.7468e-05\n",
      "Epoch 41/1000\n",
      "5571/5571 [==============================] - 0s 9us/step - loss: 1.1822e-04 - val_loss: 6.8100e-05\n",
      "Epoch 42/1000\n",
      "5571/5571 [==============================] - 0s 9us/step - loss: 1.1804e-04 - val_loss: 6.7412e-05\n",
      "Epoch 43/1000\n",
      "5571/5571 [==============================] - 0s 9us/step - loss: 1.1832e-04 - val_loss: 6.7440e-05\n",
      "Epoch 44/1000\n",
      "5571/5571 [==============================] - 0s 10us/step - loss: 1.1754e-04 - val_loss: 6.7947e-05\n",
      "Epoch 45/1000\n",
      "5571/5571 [==============================] - 0s 10us/step - loss: 1.1706e-04 - val_loss: 6.7165e-05\n",
      "Epoch 46/1000\n",
      "5571/5571 [==============================] - 0s 10us/step - loss: 1.1684e-04 - val_loss: 6.8311e-05\n",
      "Epoch 47/1000\n",
      "5571/5571 [==============================] - 0s 9us/step - loss: 1.1698e-04 - val_loss: 7.0574e-05\n",
      "Epoch 48/1000\n",
      "5571/5571 [==============================] - 0s 10us/step - loss: 1.1735e-04 - val_loss: 6.8713e-05\n",
      "Epoch 49/1000\n",
      "5571/5571 [==============================] - 0s 10us/step - loss: 1.1759e-04 - val_loss: 6.8241e-05\n",
      "Epoch 50/1000\n",
      "5571/5571 [==============================] - 0s 10us/step - loss: 1.1686e-04 - val_loss: 6.6677e-05\n",
      "Epoch 51/1000\n",
      "5571/5571 [==============================] - 0s 10us/step - loss: 1.1670e-04 - val_loss: 6.5888e-05\n",
      "Epoch 52/1000\n",
      "5571/5571 [==============================] - 0s 10us/step - loss: 1.1639e-04 - val_loss: 6.6002e-05\n",
      "Epoch 53/1000\n",
      "5571/5571 [==============================] - 0s 10us/step - loss: 1.1588e-04 - val_loss: 6.7662e-05\n",
      "Epoch 54/1000\n",
      "5571/5571 [==============================] - 0s 9us/step - loss: 1.1659e-04 - val_loss: 6.6342e-05\n",
      "Epoch 55/1000\n",
      "5571/5571 [==============================] - 0s 10us/step - loss: 1.1561e-04 - val_loss: 6.5359e-05\n",
      "Epoch 56/1000\n",
      "5571/5571 [==============================] - 0s 9us/step - loss: 1.1534e-04 - val_loss: 6.6565e-05\n",
      "Epoch 57/1000\n",
      "5571/5571 [==============================] - 0s 10us/step - loss: 1.1548e-04 - val_loss: 6.7227e-05\n",
      "Epoch 58/1000\n",
      "5571/5571 [==============================] - 0s 9us/step - loss: 1.1576e-04 - val_loss: 6.5996e-05\n",
      "Epoch 59/1000\n",
      "5571/5571 [==============================] - 0s 9us/step - loss: 1.1568e-04 - val_loss: 6.5448e-05\n",
      "Epoch 60/1000\n",
      "5571/5571 [==============================] - 0s 9us/step - loss: 1.1511e-04 - val_loss: 6.4848e-05\n",
      "Epoch 61/1000\n",
      "5571/5571 [==============================] - 0s 9us/step - loss: 1.1519e-04 - val_loss: 6.5802e-05\n",
      "Epoch 62/1000\n",
      "5571/5571 [==============================] - 0s 10us/step - loss: 1.1437e-04 - val_loss: 6.5365e-05\n",
      "Epoch 63/1000\n",
      "5571/5571 [==============================] - 0s 9us/step - loss: 1.1478e-04 - val_loss: 6.5858e-05\n",
      "Epoch 64/1000\n",
      "5571/5571 [==============================] - 0s 9us/step - loss: 1.1450e-04 - val_loss: 6.4725e-05\n",
      "Epoch 65/1000\n",
      "5571/5571 [==============================] - 0s 9us/step - loss: 1.1395e-04 - val_loss: 6.5423e-05\n",
      "Epoch 66/1000\n",
      "5571/5571 [==============================] - 0s 9us/step - loss: 1.1456e-04 - val_loss: 6.5487e-05\n",
      "Epoch 67/1000\n",
      "5571/5571 [==============================] - 0s 9us/step - loss: 1.1407e-04 - val_loss: 6.4516e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68/1000\n",
      "5571/5571 [==============================] - 0s 9us/step - loss: 1.1438e-04 - val_loss: 6.5389e-05\n",
      "Epoch 69/1000\n",
      "5571/5571 [==============================] - 0s 9us/step - loss: 1.1385e-04 - val_loss: 6.3950e-05\n",
      "Epoch 70/1000\n",
      "5571/5571 [==============================] - 0s 9us/step - loss: 1.1344e-04 - val_loss: 6.4038e-05\n",
      "Epoch 71/1000\n",
      "5571/5571 [==============================] - 0s 10us/step - loss: 1.1408e-04 - val_loss: 6.4776e-05\n",
      "Epoch 72/1000\n",
      "5571/5571 [==============================] - 0s 9us/step - loss: 1.1318e-04 - val_loss: 6.3693e-05\n",
      "Epoch 73/1000\n",
      "5571/5571 [==============================] - 0s 9us/step - loss: 1.1275e-04 - val_loss: 6.4754e-05\n",
      "Epoch 74/1000\n",
      "5571/5571 [==============================] - 0s 9us/step - loss: 1.1343e-04 - val_loss: 6.4569e-05\n",
      "Epoch 75/1000\n",
      "5571/5571 [==============================] - 0s 10us/step - loss: 1.1352e-04 - val_loss: 6.5678e-05\n",
      "Epoch 76/1000\n",
      "5571/5571 [==============================] - 0s 10us/step - loss: 1.1253e-04 - val_loss: 6.3192e-05\n",
      "Epoch 77/1000\n",
      "5571/5571 [==============================] - 0s 10us/step - loss: 1.1194e-04 - val_loss: 6.3767e-05\n",
      "Epoch 78/1000\n",
      "5571/5571 [==============================] - 0s 10us/step - loss: 1.1186e-04 - val_loss: 6.4086e-05\n",
      "Epoch 79/1000\n",
      "5571/5571 [==============================] - 0s 10us/step - loss: 1.1161e-04 - val_loss: 6.4936e-05\n",
      "Epoch 80/1000\n",
      "5571/5571 [==============================] - 0s 10us/step - loss: 1.1185e-04 - val_loss: 6.6738e-05\n",
      "Epoch 81/1000\n",
      "5571/5571 [==============================] - 0s 10us/step - loss: 1.1191e-04 - val_loss: 6.3614e-05\n",
      "Epoch 82/1000\n",
      "5571/5571 [==============================] - 0s 9us/step - loss: 1.1127e-04 - val_loss: 6.2718e-05\n",
      "Epoch 83/1000\n",
      "5571/5571 [==============================] - 0s 9us/step - loss: 1.1200e-04 - val_loss: 6.5322e-05\n",
      "Epoch 84/1000\n",
      "5571/5571 [==============================] - 0s 10us/step - loss: 1.1126e-04 - val_loss: 6.2918e-05\n",
      "Epoch 85/1000\n",
      "5571/5571 [==============================] - 0s 10us/step - loss: 1.1240e-04 - val_loss: 6.2065e-05\n",
      "Epoch 86/1000\n",
      "5571/5571 [==============================] - 0s 10us/step - loss: 1.1055e-04 - val_loss: 6.2013e-05\n",
      "Epoch 87/1000\n",
      "5571/5571 [==============================] - 0s 10us/step - loss: 1.1037e-04 - val_loss: 6.1741e-05\n",
      "Epoch 88/1000\n",
      "5571/5571 [==============================] - 0s 10us/step - loss: 1.1059e-04 - val_loss: 6.3123e-05\n",
      "Epoch 89/1000\n",
      "5571/5571 [==============================] - 0s 10us/step - loss: 1.1097e-04 - val_loss: 6.1708e-05\n",
      "Epoch 90/1000\n",
      "5571/5571 [==============================] - 0s 10us/step - loss: 1.1023e-04 - val_loss: 6.1693e-05\n",
      "Epoch 91/1000\n",
      "5571/5571 [==============================] - 0s 10us/step - loss: 1.1017e-04 - val_loss: 6.1514e-05\n",
      "Epoch 92/1000\n",
      "5571/5571 [==============================] - 0s 9us/step - loss: 1.1041e-04 - val_loss: 6.5979e-05\n",
      "Epoch 93/1000\n",
      "5571/5571 [==============================] - 0s 9us/step - loss: 1.0932e-04 - val_loss: 6.3594e-05\n",
      "Epoch 94/1000\n",
      "5571/5571 [==============================] - 0s 10us/step - loss: 1.1002e-04 - val_loss: 6.0947e-05\n",
      "Epoch 95/1000\n",
      "5571/5571 [==============================] - 0s 14us/step - loss: 1.0988e-04 - val_loss: 6.2536e-05\n",
      "Epoch 96/1000\n",
      "5571/5571 [==============================] - 0s 10us/step - loss: 1.1028e-04 - val_loss: 6.1693e-05\n",
      "Epoch 97/1000\n",
      "5571/5571 [==============================] - 0s 10us/step - loss: 1.0867e-04 - val_loss: 6.1636e-05\n",
      "Epoch 98/1000\n",
      "5571/5571 [==============================] - 0s 10us/step - loss: 1.0891e-04 - val_loss: 6.6029e-05\n",
      "Epoch 99/1000\n",
      "5571/5571 [==============================] - 0s 10us/step - loss: 1.0880e-04 - val_loss: 6.4682e-05\n",
      "Epoch 100/1000\n",
      "5571/5571 [==============================] - 0s 10us/step - loss: 1.0924e-04 - val_loss: 6.4923e-05\n",
      "Epoch 101/1000\n",
      "5571/5571 [==============================] - 0s 10us/step - loss: 1.0831e-04 - val_loss: 6.1199e-05\n",
      "Epoch 102/1000\n",
      "5571/5571 [==============================] - 0s 10us/step - loss: 1.0873e-04 - val_loss: 6.3035e-05\n",
      "Epoch 103/1000\n",
      "5571/5571 [==============================] - 0s 10us/step - loss: 1.0920e-04 - val_loss: 6.1311e-05\n",
      "Epoch 104/1000\n",
      "5571/5571 [==============================] - 0s 10us/step - loss: 1.0745e-04 - val_loss: 5.9995e-05\n",
      "Epoch 105/1000\n",
      "5571/5571 [==============================] - 0s 10us/step - loss: 1.0828e-04 - val_loss: 5.9979e-05\n",
      "Epoch 106/1000\n",
      "5571/5571 [==============================] - 0s 10us/step - loss: 1.0838e-04 - val_loss: 6.2289e-05\n",
      "Epoch 107/1000\n",
      "5571/5571 [==============================] - 0s 9us/step - loss: 1.0796e-04 - val_loss: 6.3046e-05\n",
      "Epoch 108/1000\n",
      "5571/5571 [==============================] - 0s 9us/step - loss: 1.0768e-04 - val_loss: 6.0890e-05\n",
      "Epoch 109/1000\n",
      "5571/5571 [==============================] - 0s 9us/step - loss: 1.0811e-04 - val_loss: 6.7078e-05\n",
      "Epoch 110/1000\n",
      "5571/5571 [==============================] - 0s 9us/step - loss: 1.0768e-04 - val_loss: 5.8472e-05\n",
      "Epoch 111/1000\n",
      "5571/5571 [==============================] - 0s 10us/step - loss: 1.0700e-04 - val_loss: 6.0726e-05\n",
      "Epoch 112/1000\n",
      "5571/5571 [==============================] - 0s 10us/step - loss: 1.0709e-04 - val_loss: 6.1635e-05\n",
      "Epoch 113/1000\n",
      "5571/5571 [==============================] - 0s 10us/step - loss: 1.0791e-04 - val_loss: 6.0103e-05\n",
      "Epoch 114/1000\n",
      "5571/5571 [==============================] - 0s 10us/step - loss: 1.0736e-04 - val_loss: 6.0858e-05\n",
      "Epoch 115/1000\n",
      "5571/5571 [==============================] - 0s 10us/step - loss: 1.0643e-04 - val_loss: 5.9877e-05\n",
      "Epoch 116/1000\n",
      "5571/5571 [==============================] - 0s 9us/step - loss: 1.0669e-04 - val_loss: 5.8317e-05\n",
      "Epoch 117/1000\n",
      "5571/5571 [==============================] - 0s 9us/step - loss: 1.0615e-04 - val_loss: 6.2128e-05\n",
      "Epoch 118/1000\n",
      "5571/5571 [==============================] - 0s 10us/step - loss: 1.0548e-04 - val_loss: 5.8408e-05\n",
      "Epoch 119/1000\n",
      "5571/5571 [==============================] - 0s 10us/step - loss: 1.0521e-04 - val_loss: 5.7563e-05\n",
      "Epoch 120/1000\n",
      "5571/5571 [==============================] - 0s 10us/step - loss: 1.0539e-04 - val_loss: 5.9399e-05\n",
      "Epoch 121/1000\n",
      "5571/5571 [==============================] - 0s 10us/step - loss: 1.0664e-04 - val_loss: 5.8081e-05\n",
      "Epoch 122/1000\n",
      "5571/5571 [==============================] - 0s 10us/step - loss: 1.0685e-04 - val_loss: 6.0853e-05\n",
      "Epoch 123/1000\n",
      "5571/5571 [==============================] - 0s 10us/step - loss: 1.0605e-04 - val_loss: 5.8721e-05\n",
      "Epoch 124/1000\n",
      "5571/5571 [==============================] - 0s 10us/step - loss: 1.0728e-04 - val_loss: 5.8658e-05\n",
      "Epoch 125/1000\n",
      "5571/5571 [==============================] - 0s 10us/step - loss: 1.0599e-04 - val_loss: 5.8422e-05\n",
      "Epoch 126/1000\n",
      "5571/5571 [==============================] - 0s 9us/step - loss: 1.0433e-04 - val_loss: 5.8971e-05\n",
      "Epoch 127/1000\n",
      "5571/5571 [==============================] - 0s 9us/step - loss: 1.0557e-04 - val_loss: 6.1650e-05\n",
      "Epoch 128/1000\n",
      "5571/5571 [==============================] - 0s 9us/step - loss: 1.0564e-04 - val_loss: 5.9093e-05\n",
      "Epoch 129/1000\n",
      "5571/5571 [==============================] - 0s 9us/step - loss: 1.0409e-04 - val_loss: 5.8000e-05\n",
      "Epoch 130/1000\n",
      "5571/5571 [==============================] - 0s 9us/step - loss: 1.0457e-04 - val_loss: 5.9402e-05\n",
      "Epoch 131/1000\n",
      "5571/5571 [==============================] - 0s 10us/step - loss: 1.0459e-04 - val_loss: 5.7594e-05\n",
      "Epoch 132/1000\n",
      "5571/5571 [==============================] - 0s 10us/step - loss: 1.0383e-04 - val_loss: 5.6937e-05\n",
      "Epoch 133/1000\n",
      "5571/5571 [==============================] - 0s 10us/step - loss: 1.0329e-04 - val_loss: 5.7466e-05\n",
      "Epoch 134/1000\n",
      "5571/5571 [==============================] - 0s 10us/step - loss: 1.0404e-04 - val_loss: 5.6371e-05\n",
      "Epoch 135/1000\n",
      "5571/5571 [==============================] - 0s 10us/step - loss: 1.0313e-04 - val_loss: 5.7229e-05\n",
      "Epoch 136/1000\n",
      "5571/5571 [==============================] - 0s 10us/step - loss: 1.0326e-04 - val_loss: 5.6170e-05\n",
      "Epoch 137/1000\n",
      "5571/5571 [==============================] - 0s 10us/step - loss: 1.0394e-04 - val_loss: 5.6589e-05\n",
      "Epoch 138/1000\n",
      "5571/5571 [==============================] - 0s 10us/step - loss: 1.0467e-04 - val_loss: 5.7533e-05\n",
      "Epoch 139/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5571/5571 [==============================] - 0s 9us/step - loss: 1.0480e-04 - val_loss: 5.8209e-05\n",
      "Epoch 140/1000\n",
      "5571/5571 [==============================] - 0s 9us/step - loss: 1.0273e-04 - val_loss: 5.5314e-05\n",
      "Epoch 141/1000\n",
      "5571/5571 [==============================] - 0s 9us/step - loss: 1.0250e-04 - val_loss: 5.6000e-05\n",
      "Epoch 142/1000\n",
      "5571/5571 [==============================] - 0s 9us/step - loss: 1.0299e-04 - val_loss: 5.6068e-05\n",
      "Epoch 143/1000\n",
      "5571/5571 [==============================] - 0s 10us/step - loss: 1.0181e-04 - val_loss: 5.8658e-05\n",
      "Epoch 144/1000\n",
      "5571/5571 [==============================] - 0s 10us/step - loss: 1.0311e-04 - val_loss: 5.7503e-05\n",
      "Epoch 145/1000\n",
      "5571/5571 [==============================] - 0s 9us/step - loss: 1.0303e-04 - val_loss: 5.6124e-05\n",
      "Epoch 146/1000\n",
      "5571/5571 [==============================] - 0s 9us/step - loss: 1.0207e-04 - val_loss: 5.8126e-05\n",
      "Epoch 147/1000\n",
      "5571/5571 [==============================] - 0s 10us/step - loss: 1.0261e-04 - val_loss: 5.5148e-05\n",
      "Epoch 148/1000\n",
      "5571/5571 [==============================] - 0s 9us/step - loss: 1.0218e-04 - val_loss: 5.9286e-05\n",
      "Epoch 149/1000\n",
      "5571/5571 [==============================] - 0s 9us/step - loss: 1.0208e-04 - val_loss: 5.5793e-05\n",
      "Epoch 150/1000\n",
      "5571/5571 [==============================] - 0s 10us/step - loss: 1.0217e-04 - val_loss: 5.4799e-05\n",
      "Epoch 151/1000\n",
      "5571/5571 [==============================] - 0s 9us/step - loss: 1.0217e-04 - val_loss: 5.4115e-05\n",
      "Epoch 152/1000\n",
      "5571/5571 [==============================] - 0s 9us/step - loss: 1.0118e-04 - val_loss: 5.5525e-05\n",
      "Epoch 153/1000\n",
      "5571/5571 [==============================] - 0s 9us/step - loss: 1.0076e-04 - val_loss: 5.3885e-05\n",
      "Epoch 154/1000\n",
      "5571/5571 [==============================] - 0s 10us/step - loss: 1.0059e-04 - val_loss: 5.6658e-05\n",
      "Epoch 155/1000\n",
      "5571/5571 [==============================] - 0s 9us/step - loss: 1.0057e-04 - val_loss: 5.3490e-05\n",
      "Epoch 156/1000\n",
      "5571/5571 [==============================] - 0s 9us/step - loss: 1.0136e-04 - val_loss: 5.5608e-05\n",
      "Epoch 157/1000\n",
      "5571/5571 [==============================] - 0s 10us/step - loss: 1.0197e-04 - val_loss: 5.8366e-05\n",
      "Epoch 158/1000\n",
      "5571/5571 [==============================] - 0s 10us/step - loss: 1.0142e-04 - val_loss: 5.5082e-05\n",
      "Epoch 159/1000\n",
      "5571/5571 [==============================] - 0s 9us/step - loss: 1.0137e-04 - val_loss: 5.4120e-05\n",
      "Epoch 160/1000\n",
      "5571/5571 [==============================] - 0s 10us/step - loss: 1.0051e-04 - val_loss: 5.4059e-05\n",
      "Epoch 161/1000\n",
      "5571/5571 [==============================] - 0s 10us/step - loss: 1.0131e-04 - val_loss: 5.4105e-05\n",
      "Epoch 162/1000\n",
      "5571/5571 [==============================] - 0s 10us/step - loss: 9.9984e-05 - val_loss: 5.3302e-05\n",
      "Epoch 163/1000\n",
      "5571/5571 [==============================] - 0s 10us/step - loss: 9.9266e-05 - val_loss: 5.3161e-05\n",
      "Epoch 164/1000\n",
      "5571/5571 [==============================] - 0s 10us/step - loss: 1.0031e-04 - val_loss: 5.4222e-05\n",
      "Epoch 165/1000\n",
      "5571/5571 [==============================] - 0s 10us/step - loss: 9.9413e-05 - val_loss: 5.2446e-05\n",
      "Epoch 166/1000\n",
      "5571/5571 [==============================] - 0s 9us/step - loss: 1.0051e-04 - val_loss: 5.5729e-05\n",
      "Epoch 167/1000\n",
      "5571/5571 [==============================] - 0s 9us/step - loss: 9.9800e-05 - val_loss: 5.2929e-05\n",
      "Epoch 168/1000\n",
      "5571/5571 [==============================] - 0s 10us/step - loss: 9.8889e-05 - val_loss: 5.2454e-05\n",
      "Epoch 169/1000\n",
      "5571/5571 [==============================] - 0s 9us/step - loss: 9.9558e-05 - val_loss: 5.5375e-05\n",
      "Epoch 170/1000\n",
      "5571/5571 [==============================] - 0s 9us/step - loss: 1.0021e-04 - val_loss: 5.5024e-05\n",
      "Epoch 171/1000\n",
      "5571/5571 [==============================] - 0s 10us/step - loss: 9.8266e-05 - val_loss: 5.4422e-05\n",
      "Epoch 172/1000\n",
      "5571/5571 [==============================] - 0s 9us/step - loss: 9.8611e-05 - val_loss: 5.1899e-05\n",
      "Epoch 173/1000\n",
      "5571/5571 [==============================] - 0s 9us/step - loss: 9.9176e-05 - val_loss: 5.3606e-05\n",
      "Epoch 174/1000\n",
      "5571/5571 [==============================] - 0s 10us/step - loss: 9.8256e-05 - val_loss: 5.1562e-05\n",
      "Epoch 175/1000\n",
      "5571/5571 [==============================] - 0s 10us/step - loss: 9.7927e-05 - val_loss: 5.3049e-05\n",
      "Epoch 176/1000\n",
      "5571/5571 [==============================] - 0s 9us/step - loss: 9.8863e-05 - val_loss: 5.1161e-05\n",
      "Epoch 177/1000\n",
      "5571/5571 [==============================] - 0s 9us/step - loss: 9.9214e-05 - val_loss: 5.0776e-05\n",
      "Epoch 178/1000\n",
      "5571/5571 [==============================] - 0s 9us/step - loss: 9.7914e-05 - val_loss: 5.5194e-05\n",
      "Epoch 179/1000\n",
      "5571/5571 [==============================] - 0s 9us/step - loss: 9.8333e-05 - val_loss: 5.2275e-05\n",
      "Epoch 180/1000\n",
      "5571/5571 [==============================] - 0s 9us/step - loss: 9.8433e-05 - val_loss: 5.1409e-05\n",
      "Epoch 181/1000\n",
      "5571/5571 [==============================] - 0s 9us/step - loss: 9.8683e-05 - val_loss: 5.9053e-05\n",
      "Epoch 182/1000\n",
      "5571/5571 [==============================] - 0s 10us/step - loss: 9.7022e-05 - val_loss: 5.4335e-05\n",
      "Epoch 183/1000\n",
      "5571/5571 [==============================] - 0s 10us/step - loss: 9.7848e-05 - val_loss: 5.1765e-05\n",
      "Epoch 184/1000\n",
      "5571/5571 [==============================] - 0s 10us/step - loss: 9.7433e-05 - val_loss: 5.0158e-05\n",
      "Epoch 185/1000\n",
      "5571/5571 [==============================] - 0s 10us/step - loss: 9.6686e-05 - val_loss: 5.1788e-05\n",
      "Epoch 186/1000\n",
      "5571/5571 [==============================] - 0s 10us/step - loss: 9.9295e-05 - val_loss: 5.1816e-05\n",
      "Epoch 187/1000\n",
      "5571/5571 [==============================] - 0s 10us/step - loss: 9.7118e-05 - val_loss: 5.3063e-05\n",
      "Epoch 188/1000\n",
      "5571/5571 [==============================] - 0s 10us/step - loss: 9.7607e-05 - val_loss: 5.0407e-05\n",
      "Epoch 189/1000\n",
      "5571/5571 [==============================] - 0s 9us/step - loss: 9.6381e-05 - val_loss: 5.1642e-05\n",
      "Epoch 190/1000\n",
      "5571/5571 [==============================] - 0s 9us/step - loss: 9.6019e-05 - val_loss: 5.1849e-05\n",
      "Epoch 191/1000\n",
      "5571/5571 [==============================] - 0s 9us/step - loss: 9.6894e-05 - val_loss: 5.3851e-05\n",
      "Epoch 192/1000\n",
      "5571/5571 [==============================] - 0s 10us/step - loss: 9.5885e-05 - val_loss: 5.6804e-05\n",
      "Epoch 193/1000\n",
      "5571/5571 [==============================] - 0s 10us/step - loss: 9.8480e-05 - val_loss: 5.2449e-05\n",
      "Epoch 194/1000\n",
      "5571/5571 [==============================] - 0s 10us/step - loss: 9.6484e-05 - val_loss: 5.0396e-05\n",
      "Epoch 195/1000\n",
      "5571/5571 [==============================] - 0s 10us/step - loss: 9.6324e-05 - val_loss: 5.3504e-05\n",
      "Epoch 196/1000\n",
      "5571/5571 [==============================] - 0s 10us/step - loss: 9.6134e-05 - val_loss: 5.3622e-05\n",
      "Epoch 197/1000\n",
      "5571/5571 [==============================] - 0s 9us/step - loss: 9.7109e-05 - val_loss: 5.0289e-05\n",
      "Epoch 198/1000\n",
      "5571/5571 [==============================] - 0s 10us/step - loss: 9.5929e-05 - val_loss: 5.2612e-05\n",
      "Epoch 199/1000\n",
      "5571/5571 [==============================] - 0s 10us/step - loss: 9.6343e-05 - val_loss: 5.7088e-05\n",
      "Epoch 200/1000\n",
      "5571/5571 [==============================] - 0s 9us/step - loss: 9.6132e-05 - val_loss: 5.0802e-05\n",
      "Epoch 201/1000\n",
      "5571/5571 [==============================] - 0s 9us/step - loss: 9.6594e-05 - val_loss: 4.9928e-05\n",
      "Epoch 202/1000\n",
      "5571/5571 [==============================] - 0s 9us/step - loss: 9.6210e-05 - val_loss: 4.9680e-05\n",
      "Epoch 00202: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x61bc35ecf8>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "mergeData()\n",
    "train=readData()\n",
    "train=changeYear(train)\n",
    "train=augFeatures(train)\n",
    "train=normalize(train)\n",
    "train_x, train_y = buildTrain(train, 1, 1)\n",
    "train_x, train_y = shuffle(train_x, train_y )\n",
    "\n",
    "# split training data and validation data\n",
    "train_x, train_y , val_x, val_y = splitData(train_x, train_y , 0.1)\n",
    "train_y = train_y[:,np.newaxis]\n",
    "val_y = val_y[:,np.newaxis]\n",
    "\n",
    "model = buildOneToOneModel(train_x.shape)\n",
    "callback = EarlyStopping(monitor=\"loss\", patience=10, verbose=1, mode=\"auto\")\n",
    "\n",
    "model.fit(train_x, train_y, epochs=1000, batch_size=128, validation_data=(val_x, val_y), callbacks=[callback])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
