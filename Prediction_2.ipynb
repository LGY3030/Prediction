{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, LSTM, TimeDistributed, RepeatVector\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.utils import np_utils\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from sklearn import preprocessing\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 把所有年份的資料merge在一起,並存在data.csv裡\n",
    "def mergeData():\n",
    "    SaveFile_Name = 'data.csv'\n",
    "    file_list = os.listdir('data')\n",
    "    df = pd.read_csv('data'+'\\\\'+file_list[0])\n",
    "    df.to_csv(SaveFile_Name,encoding=\"utf_8_sig\",index=False)\n",
    "    for i in range(1,len(file_list)):\n",
    "        df = pd.read_csv('data'+'\\\\'+file_list[i])\n",
    "        df.to_csv(SaveFile_Name,encoding=\"utf_8_sig\",index=False, header=False, mode='a+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 讀取data.csv\n",
    "def readData():\n",
    "    train = pd.read_csv(\"data.csv\")\n",
    "    return train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 把年份換成西元年\n",
    "def changeYear(data):\n",
    "    for i in range(0,data.shape[0]):\n",
    "        Date=data[\"日期\"][i].split('/')\n",
    "        year,month,date=Date[0],Date[1],Date[2]\n",
    "        year=str(int(year)+1911)\n",
    "        data.loc[i,\"日期\"]=year+'/'+month+'/'+date\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 增加features(\"年\",\"月\",\"日\",\"第幾日\")\n",
    "def augFeatures(data):\n",
    "  data[\"日期\"] = pd.to_datetime(data[\"日期\"])\n",
    "  data[\"年\"] = data[\"日期\"].dt.year\n",
    "  data[\"月\"] = data[\"日期\"].dt.month\n",
    "  data[\"日\"] = data[\"日期\"].dt.day\n",
    "  data[\"第幾日\"] = data[\"日期\"].dt.dayofweek\n",
    "  return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 把非數字的資料換成正確資料,並減少features(\"日期\",\"成交股數\",\"成交金額\",等等...)\n",
    "def manage(data):\n",
    "    for i in range(0,data.shape[0]):\n",
    "        if data[\"漲跌價差\"][i]=='X0.00':\n",
    "            data.loc[i,\"漲跌價差\"]=str(int(data[\"收盤價\"][i])-int(data[\"收盤價\"][i-1]))\n",
    "    data=data.drop([\"日期\"], axis=1)\n",
    "    data=data.drop([\"成交股數\"], axis=1)\n",
    "    data=data.drop([\"成交金額\"], axis=1)\n",
    "    data=data.drop([\"漲跌價差\"], axis=1)\n",
    "    data=data.drop([\"成交筆數\"], axis=1)\n",
    "    data=data.convert_objects(convert_numeric=True)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 把資料normalize\n",
    "def normalize(train):\n",
    "    train = train.apply(lambda x: (x - np.mean(x)) / (np.max(x) - np.min(x)))\n",
    "    return train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 創造出train的資料,train_x為輸入資料(所有features),train_y為輸出資料(開盤價的成長率,分為9個區段)\n",
    "def buildTrain(train, pastDay=30, futureDay=1):\n",
    "    X_train, Y_train, Z_train= [], [], []\n",
    "    X,Y,Z=[],[],[]\n",
    "    for i in range(train.shape[0]-futureDay-pastDay):\n",
    "        X_train.append(np.array(train.iloc[i:i+pastDay]))\n",
    "        Y_train.append(np.array(train.iloc[i+pastDay:i+pastDay+futureDay][\"開盤價\"]))\n",
    "        Z_train.append(np.array(train.iloc[i+pastDay-1:i+pastDay][\"開盤價\"]))\n",
    "    X=np.array(X_train)\n",
    "    Y=np.array(Y_train)\n",
    "    Z=np.array(Z_train)\n",
    "    Y=100*((Y-Z)/Z)\n",
    "    Y_train=[]\n",
    "    \n",
    "    for i in range(len(Y)):\n",
    "        if Y[i]<-3.5:\n",
    "            Y_train.append(np.array([0]))\n",
    "        elif -3.5<=Y[i]<-2.5:\n",
    "            Y_train.append(np.array([1]))\n",
    "        elif -2.5<=Y[i]<-1.5:\n",
    "            Y_train.append(np.array([2]))\n",
    "        elif -1.5<=Y[i]<-0.5:\n",
    "            Y_train.append(np.array([3]))\n",
    "        elif -0.5<=Y[i]<0.5:\n",
    "            Y_train.append(np.array([4]))\n",
    "        elif 0.5<=Y[i]<1.5:\n",
    "            Y_train.append(np.array([5]))\n",
    "        elif 1.5<=Y[i]<2.5:\n",
    "            Y_train.append(np.array([6]))\n",
    "        elif 2.5<=Y[i]<3.5:\n",
    "            Y_train.append(np.array([7]))\n",
    "        elif 3.5<=Y[i]:\n",
    "            Y_train.append(np.array([8]))\n",
    "    Y=np.array(Y_train)\n",
    "    \n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 把資料打亂\n",
    "def shuffle(X,Y):\n",
    "    np.random.seed()\n",
    "    randomList = np.arange(X.shape[0])\n",
    "    np.random.shuffle(randomList)\n",
    "    return X[randomList], Y[randomList]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 將資料分成訓練資料和測試資料\n",
    "def splitData(X,Y,rate):\n",
    "    X_train = X[:-int(X.shape[0]*rate)]\n",
    "\n",
    "    Y_train = Y[:-int(Y.shape[0]*rate)]\n",
    "    \n",
    "    X_val = X[-int(X.shape[0]*rate):]\n",
    "\n",
    "    Y_val = Y[-int(Y.shape[0]*rate):]\n",
    "    return X_train, Y_train, X_val, Y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 建立模型\n",
    "def buildModel(shape):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(200, input_length=shape[1], input_dim=shape[2],return_sequences=True))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(200))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(9)) \n",
    "    model.add(Activation('softmax'))\n",
    "    model.compile(loss=\"categorical_crossentropy\", optimizer='adam',metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "class LossHistory(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.losses = {'batch':[], 'epoch':[]}\n",
    "        self.accuracy = {'batch':[], 'epoch':[]}\n",
    "        self.val_loss = {'batch':[], 'epoch':[]}\n",
    "        self.val_acc = {'batch':[], 'epoch':[]}\n",
    " \n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        self.losses['batch'].append(logs.get('loss'))\n",
    "        self.accuracy['batch'].append(logs.get('acc'))\n",
    "        self.val_loss['batch'].append(logs.get('val_loss'))\n",
    "        self.val_acc['batch'].append(logs.get('val_acc'))\n",
    " \n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        self.losses['epoch'].append(logs.get('loss'))\n",
    "        self.accuracy['epoch'].append(logs.get('acc'))\n",
    "        self.val_loss['epoch'].append(logs.get('val_loss'))\n",
    "        self.val_acc['epoch'].append(logs.get('val_acc'))\n",
    " \n",
    "    def loss_plot(self, loss_type):\n",
    "        iters = range(len(self.losses[loss_type]))\n",
    "        plt.figure()\n",
    "        # acc\n",
    "        plt.plot(iters, self.accuracy[loss_type], 'r', label='train acc')\n",
    "        # loss\n",
    "        plt.plot(iters, self.losses[loss_type], 'g', label='train loss')\n",
    "        if loss_type == 'epoch':\n",
    "            # val_acc\n",
    "            plt.plot(iters, self.val_acc[loss_type], 'b', label='val acc')\n",
    "            # val_loss\n",
    "            plt.plot(iters, self.val_loss[loss_type], 'k', label='val loss')\n",
    "        plt.grid(True)\n",
    "        plt.xlabel(loss_type)\n",
    "        plt.ylabel('acc-loss')\n",
    "        plt.legend(loc=\"upper right\")\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:11: FutureWarning: convert_objects is deprecated.  To re-infer data dtypes for object columns, use DataFrame.infer_objects()\n",
      "For all other conversions use the data-type specific converters pd.to_datetime, pd.to_timedelta and pd.to_numeric.\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "C:\\Users\\admin\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: The `input_dim` and `input_length` arguments in recurrent layers are deprecated. Use `input_shape` instead.\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\Users\\admin\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(200, input_shape=(1, 8), return_sequences=True)`\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_3 (LSTM)                (None, 1, 200)            167200    \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 1, 200)            0         \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 9)                 1809      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 9)                 0         \n",
      "=================================================================\n",
      "Total params: 489,809\n",
      "Trainable params: 489,809\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 5013 samples, validate on 558 samples\n",
      "Epoch 1/1000\n",
      " - 3s - loss: 2.1435 - acc: 0.2330 - val_loss: 2.0390 - val_acc: 0.2348\n",
      "Epoch 2/1000\n",
      " - 1s - loss: 1.9921 - acc: 0.2392 - val_loss: 1.9710 - val_acc: 0.2366\n",
      "Epoch 3/1000\n",
      " - 1s - loss: 1.9786 - acc: 0.2420 - val_loss: 1.9615 - val_acc: 0.2401\n",
      "Epoch 4/1000\n",
      " - 1s - loss: 1.9784 - acc: 0.2450 - val_loss: 1.9579 - val_acc: 0.2312\n",
      "Epoch 5/1000\n",
      " - 1s - loss: 1.9771 - acc: 0.2472 - val_loss: 1.9573 - val_acc: 0.2348\n",
      "Epoch 6/1000\n",
      " - 1s - loss: 1.9745 - acc: 0.2505 - val_loss: 1.9576 - val_acc: 0.2330\n",
      "Epoch 7/1000\n",
      " - 1s - loss: 1.9747 - acc: 0.2492 - val_loss: 1.9565 - val_acc: 0.2312\n",
      "Epoch 8/1000\n",
      " - 1s - loss: 1.9737 - acc: 0.2492 - val_loss: 1.9566 - val_acc: 0.2294\n",
      "Epoch 9/1000\n",
      " - 1s - loss: 1.9720 - acc: 0.2509 - val_loss: 1.9531 - val_acc: 0.2276\n",
      "Epoch 10/1000\n",
      " - 1s - loss: 1.9718 - acc: 0.2468 - val_loss: 1.9528 - val_acc: 0.2312\n",
      "Epoch 11/1000\n",
      " - 1s - loss: 1.9706 - acc: 0.2498 - val_loss: 1.9535 - val_acc: 0.2294\n",
      "Epoch 12/1000\n",
      " - 1s - loss: 1.9709 - acc: 0.2503 - val_loss: 1.9541 - val_acc: 0.2312\n",
      "Epoch 13/1000\n",
      " - 1s - loss: 1.9716 - acc: 0.2488 - val_loss: 1.9540 - val_acc: 0.2294\n",
      "Epoch 14/1000\n",
      " - 1s - loss: 1.9709 - acc: 0.2513 - val_loss: 1.9549 - val_acc: 0.2294\n",
      "Epoch 15/1000\n",
      " - 1s - loss: 1.9687 - acc: 0.2486 - val_loss: 1.9547 - val_acc: 0.2348\n",
      "Epoch 16/1000\n",
      " - 1s - loss: 1.9690 - acc: 0.2486 - val_loss: 1.9541 - val_acc: 0.2294\n",
      "Epoch 17/1000\n",
      " - 1s - loss: 1.9682 - acc: 0.2496 - val_loss: 1.9551 - val_acc: 0.2312\n",
      "Epoch 18/1000\n",
      " - 1s - loss: 1.9676 - acc: 0.2503 - val_loss: 1.9531 - val_acc: 0.2330\n",
      "Epoch 19/1000\n",
      " - 1s - loss: 1.9680 - acc: 0.2500 - val_loss: 1.9539 - val_acc: 0.2330\n",
      "Epoch 20/1000\n",
      " - 1s - loss: 1.9674 - acc: 0.2503 - val_loss: 1.9554 - val_acc: 0.2294\n",
      "Epoch 21/1000\n",
      " - 1s - loss: 1.9681 - acc: 0.2496 - val_loss: 1.9524 - val_acc: 0.2312\n",
      "Epoch 22/1000\n",
      " - 1s - loss: 1.9689 - acc: 0.2501 - val_loss: 1.9530 - val_acc: 0.2330\n",
      "Epoch 23/1000\n",
      " - 1s - loss: 1.9671 - acc: 0.2472 - val_loss: 1.9525 - val_acc: 0.2330\n",
      "Epoch 24/1000\n",
      " - 1s - loss: 1.9667 - acc: 0.2478 - val_loss: 1.9529 - val_acc: 0.2294\n",
      "Epoch 25/1000\n",
      " - 1s - loss: 1.9661 - acc: 0.2486 - val_loss: 1.9528 - val_acc: 0.2312\n",
      "Epoch 26/1000\n",
      " - 1s - loss: 1.9652 - acc: 0.2482 - val_loss: 1.9518 - val_acc: 0.2294\n",
      "Epoch 27/1000\n",
      " - 1s - loss: 1.9648 - acc: 0.2494 - val_loss: 1.9537 - val_acc: 0.2294\n",
      "Epoch 28/1000\n",
      " - 1s - loss: 1.9660 - acc: 0.2488 - val_loss: 1.9531 - val_acc: 0.2294\n",
      "Epoch 29/1000\n",
      " - 1s - loss: 1.9658 - acc: 0.2500 - val_loss: 1.9521 - val_acc: 0.2294\n",
      "Epoch 30/1000\n",
      " - 1s - loss: 1.9657 - acc: 0.2480 - val_loss: 1.9542 - val_acc: 0.2294\n",
      "Epoch 31/1000\n",
      " - 1s - loss: 1.9663 - acc: 0.2494 - val_loss: 1.9510 - val_acc: 0.2294\n",
      "Epoch 32/1000\n",
      " - 1s - loss: 1.9646 - acc: 0.2498 - val_loss: 1.9527 - val_acc: 0.2294\n",
      "Epoch 33/1000\n",
      " - 1s - loss: 1.9644 - acc: 0.2478 - val_loss: 1.9534 - val_acc: 0.2294\n",
      "Epoch 34/1000\n",
      " - 1s - loss: 1.9646 - acc: 0.2488 - val_loss: 1.9557 - val_acc: 0.2294\n",
      "Epoch 35/1000\n",
      " - 1s - loss: 1.9634 - acc: 0.2492 - val_loss: 1.9534 - val_acc: 0.2294\n",
      "Epoch 36/1000\n",
      " - 1s - loss: 1.9624 - acc: 0.2500 - val_loss: 1.9527 - val_acc: 0.2294\n",
      "Epoch 37/1000\n",
      " - 1s - loss: 1.9637 - acc: 0.2492 - val_loss: 1.9533 - val_acc: 0.2294\n",
      "Epoch 38/1000\n",
      " - 1s - loss: 1.9637 - acc: 0.2494 - val_loss: 1.9534 - val_acc: 0.2276\n",
      "Epoch 39/1000\n",
      " - 1s - loss: 1.9629 - acc: 0.2494 - val_loss: 1.9537 - val_acc: 0.2294\n",
      "Epoch 40/1000\n",
      " - 1s - loss: 1.9636 - acc: 0.2509 - val_loss: 1.9535 - val_acc: 0.2294\n",
      "Epoch 41/1000\n",
      " - 1s - loss: 1.9623 - acc: 0.2500 - val_loss: 1.9529 - val_acc: 0.2294\n",
      "Epoch 42/1000\n",
      " - 1s - loss: 1.9614 - acc: 0.2486 - val_loss: 1.9539 - val_acc: 0.2276\n",
      "Epoch 43/1000\n",
      " - 1s - loss: 1.9624 - acc: 0.2480 - val_loss: 1.9533 - val_acc: 0.2276\n",
      "Epoch 44/1000\n",
      " - 1s - loss: 1.9630 - acc: 0.2488 - val_loss: 1.9560 - val_acc: 0.2276\n",
      "Epoch 45/1000\n",
      " - 1s - loss: 1.9630 - acc: 0.2478 - val_loss: 1.9522 - val_acc: 0.2258\n",
      "Epoch 46/1000\n",
      " - 1s - loss: 1.9616 - acc: 0.2490 - val_loss: 1.9525 - val_acc: 0.2276\n",
      "Epoch 47/1000\n",
      " - 1s - loss: 1.9609 - acc: 0.2482 - val_loss: 1.9511 - val_acc: 0.2294\n",
      "Epoch 48/1000\n",
      " - 1s - loss: 1.9625 - acc: 0.2509 - val_loss: 1.9536 - val_acc: 0.2276\n",
      "Epoch 49/1000\n",
      " - 1s - loss: 1.9603 - acc: 0.2488 - val_loss: 1.9518 - val_acc: 0.2276\n",
      "Epoch 50/1000\n",
      " - 1s - loss: 1.9605 - acc: 0.2507 - val_loss: 1.9521 - val_acc: 0.2276\n",
      "Epoch 51/1000\n",
      " - 1s - loss: 1.9617 - acc: 0.2498 - val_loss: 1.9517 - val_acc: 0.2276\n",
      "Epoch 52/1000\n",
      " - 1s - loss: 1.9600 - acc: 0.2509 - val_loss: 1.9512 - val_acc: 0.2276\n",
      "Epoch 53/1000\n",
      " - 1s - loss: 1.9601 - acc: 0.2529 - val_loss: 1.9513 - val_acc: 0.2276\n",
      "Epoch 54/1000\n",
      " - 1s - loss: 1.9601 - acc: 0.2494 - val_loss: 1.9542 - val_acc: 0.2276\n",
      "Epoch 55/1000\n",
      " - 1s - loss: 1.9601 - acc: 0.2488 - val_loss: 1.9518 - val_acc: 0.2330\n",
      "Epoch 56/1000\n",
      " - 1s - loss: 1.9588 - acc: 0.2515 - val_loss: 1.9520 - val_acc: 0.2258\n",
      "Epoch 57/1000\n"
     ]
    }
   ],
   "source": [
    "mergeData()\n",
    "train=readData()\n",
    "train=changeYear(train)\n",
    "train=augFeatures(train)\n",
    "train=manage(train)\n",
    "temp=train\n",
    "train=normalize(train)\n",
    "train_x1, train_y1 = buildTrain(train,1,1)\n",
    "train_x2, train_y2 = buildTrain(temp,1,1)\n",
    "train_x, train_y = train_x1,train_y2 \n",
    "train_y=np_utils.to_categorical(train_y)\n",
    "train_x, train_y = shuffle(train_x, train_y )\n",
    "train_x, train_y , test_x, test_y = splitData(train_x, train_y , 0.1)\n",
    "history = LossHistory()\n",
    "model = buildModel(train_x.shape)\n",
    "callback = EarlyStopping(monitor=\"loss\", patience=10, verbose=1, mode=\"auto\")\n",
    "model.fit(train_x, train_y, epochs=1000, batch_size=128, verbose=2,validation_split=0.1, callbacks=[callback,history])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history.loss_plot('epoch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy = model.evaluate(test_x, test_y)\n",
    "\n",
    "print('test loss: ', loss)\n",
    "print('test accuracy: ', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
